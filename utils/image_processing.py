import cv2
import numpy as np
from PIL import Image
import tensorflow as tf

class ImageProcessor:
    """
    Clase para procesamiento de imÃ¡genes y preparaciÃ³n para ML
    """
    
    def __init__(self):
        """Inicializar el procesador de imÃ¡genes"""
        self.target_size = (224, 224)  # TamaÃ±o estÃ¡ndar para modelos de clasificaciÃ³n
        
    def preprocess_for_classification(self, image):
        """
        Preprocesar imagen para clasificaciÃ³n con modelo de ML
        
        Args:
            image (numpy.ndarray): Imagen de entrada
            
        Returns:
            numpy.ndarray: Imagen preprocesada
        """
        if image is None:
            return None
            
        # Convertir de BGR a RGB si es necesario
        if len(image.shape) == 3 and image.shape[2] == 3:
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        else:
            image_rgb = image
            
        # Redimensionar a tamaÃ±o objetivo
        resized = cv2.resize(image_rgb, self.target_size)
        
        # Normalizar valores de pixel (0-255 -> 0-1)
        normalized = resized.astype(np.float32) / 255.0
        
        # Expandir dimensiones para batch
        batched = np.expand_dims(normalized, axis=0)
        
        return batched
        
    def enhance_image(self, image):
        """
        Mejorar la calidad de la imagen usando tÃ©cnicas de PDI
        
        Args:
            image (numpy.ndarray): Imagen de entrada
            
        Returns:
            numpy.ndarray: Imagen mejorada
        """
        if image is None:
            return None
            
        enhanced = image.copy()
        
        # 1. ReducciÃ³n de ruido
        enhanced = cv2.medianBlur(enhanced, 5)
        
        # 2. Mejora de contraste usando CLAHE
        if len(enhanced.shape) == 3:
            # Para imÃ¡genes en color, aplicar CLAHE en el canal L del espacio LAB
            lab = cv2.cvtColor(enhanced, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            
            clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
            l = clahe.apply(l)
            
            enhanced = cv2.merge([l, a, b])
            enhanced = cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)
        else:
            # Para imÃ¡genes en escala de grises
            clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
            enhanced = clahe.apply(enhanced)
            
        # 3. Enfoque (sharpening)
        kernel = np.array([[-1,-1,-1],
                          [-1, 9,-1],
                          [-1,-1,-1]])
        enhanced = cv2.filter2D(enhanced, -1, kernel)
        
        return enhanced
        
    def detect_objects(self, image):
        """
        Detectar objetos en la imagen usando tÃ©cnicas de visiÃ³n por computadora
        
        Args:
            image (numpy.ndarray): Imagen de entrada
            
        Returns:
            list: Lista de bounding boxes de objetos detectados
        """
        if image is None:
            return []
            
        # Convertir a escala de grises
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # Aplicar filtro Gaussiano
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)
        
        # DetecciÃ³n de bordes usando Canny
        edges = cv2.Canny(blurred, 50, 150)
        
        # Encontrar contornos
        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # Filtrar contornos por Ã¡rea
        min_area = 1000
        valid_contours = [c for c in contours if cv2.contourArea(c) > min_area]
        
        # Crear bounding boxes
        bboxes = []
        for contour in valid_contours:
            x, y, w, h = cv2.boundingRect(contour)
            bboxes.append((x, y, x+w, y+h))
            
        return bboxes
        
    def crop_largest_object(self, image):
        """
        Recortar el objeto mÃ¡s grande de la imagen
        
        Args:
            image (numpy.ndarray): Imagen de entrada
            
        Returns:
            numpy.ndarray: Imagen recortada del objeto mÃ¡s grande
        """
        bboxes = self.detect_objects(image)
        
        if not bboxes:
            return image
            
        # Encontrar el bbox mÃ¡s grande
        largest_bbox = max(bboxes, key=lambda b: (b[2]-b[0]) * (b[3]-b[1]))
        x1, y1, x2, y2 = largest_bbox
        
        # Agregar padding
        padding = 20
        h, w = image.shape[:2]
        x1 = max(0, x1 - padding)
        y1 = max(0, y1 - padding)
        x2 = min(w, x2 + padding)
        y2 = min(h, y2 + padding)
        
        # Recortar
        cropped = image[y1:y2, x1:x2]
        
        return cropped
        
    def apply_filters(self, image, filter_type="enhance"):
        """
        Aplicar diferentes filtros a la imagen
        
        Args:
            image (numpy.ndarray): Imagen de entrada
            filter_type (str): Tipo de filtro a aplicar
            
        Returns:
            numpy.ndarray: Imagen con filtro aplicado
        """
        if image is None:
            return None
            
        if filter_type == "enhance":
            return self.enhance_image(image)
        elif filter_type == "blur":
            return cv2.GaussianBlur(image, (15, 15), 0)
        elif filter_type == "sharp":
            kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
            return cv2.filter2D(image, -1, kernel)
        elif filter_type == "edge":
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            edges = cv2.Canny(gray, 50, 150)
            return cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)
        else:
            return image
            
    def create_histogram(self, image):
        """
        Crear histograma de la imagen
        
        Args:
            image (numpy.ndarray): Imagen de entrada
            
        Returns:
            dict: Histogramas por canal
        """
        if image is None:
            return None
            
        histograms = {}
        
        if len(image.shape) == 3:
            # Imagen en color
            colors = ['b', 'g', 'r']
            for i, color in enumerate(colors):
                hist = cv2.calcHist([image], [i], None, [256], [0, 256])
                histograms[color] = hist
        else:
            # Imagen en escala de grises
            hist = cv2.calcHist([image], [0], None, [256], [0, 256])
            histograms['gray'] = hist
            
        return histograms
        
    def segment_image(self, image, method="kmeans"):
        """
        Segmentar imagen usando diferentes mÃ©todos
        
        Args:
            image (numpy.ndarray): Imagen de entrada
            method (str): MÃ©todo de segmentaciÃ³n
            
        Returns:
            numpy.ndarray: Imagen segmentada
        """
        if image is None:
            return None
            
        if method == "kmeans":
            # K-means clustering
            data = image.reshape((-1, 3))
            data = np.float32(data)
            
            criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 20, 1.0)
            k = 3
            _, labels, centers = cv2.kmeans(data, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)
            
            centers = np.uint8(centers)
            segmented = centers[labels.flatten()]
            segmented = segmented.reshape(image.shape)
            
            return segmented
            
        elif method == "watershed":
            # Watershed algorithm
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
            
            # Operaciones morfolÃ³gicas
            kernel = np.ones((3,3), np.uint8)
            opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)
            
            # Ãrea de fondo segura
            sure_bg = cv2.dilate(opening, kernel, iterations=3)
            
            # Ãrea de primer plano segura
            dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)
            _, sure_fg = cv2.threshold(dist_transform, 0.7*dist_transform.max(), 255, 0)
            
            # RegiÃ³n desconocida
            sure_fg = np.uint8(sure_fg)
            unknown = cv2.subtract(sure_bg, sure_fg)
            
            # Etiquetas de marcadores
            _, markers = cv2.connectedComponents(sure_fg)
            markers = markers + 1
            markers[unknown == 255] = 0
            
            markers = cv2.watershed(image, markers)
            image[markers == -1] = [255, 0, 0]
            
            return image
            
        return image

    # Nuevas utilidades de caracterÃ­sticas visuales
    def compute_visual_features(self, image):
        """Calcular rasgos visuales bÃ¡sicos de la escena.

        Returns:
            dict: {dominant_color_rgb, dominant_color_hex, relative_size, bbox}
        """
        if image is None:
            return {}

        h, w = image.shape[:2]
        total_area = float(h * w)

        # BBox del objeto mayor
        bboxes = self.detect_objects(image)
        bbox = None
        relative_size = None
        if bboxes:
            x1, y1, x2, y2 = max(bboxes, key=lambda b: (b[2]-b[0])*(b[3]-b[1]))
            bbox = (int(x1), int(y1), int(x2), int(y2))
            area = float((x2 - x1) * (y2 - y1))
            if total_area > 0:
                relative_size = area / total_area

        # Color dominante (kmeans k=3 sobre muestreo)
        sample = cv2.resize(image, (64, 64))
        data = sample.reshape((-1, 3)).astype(np.float32)
        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)
        _, labels, centers = cv2.kmeans(data, 3, None, criteria, 5, cv2.KMEANS_RANDOM_CENTERS)
        counts = np.bincount(labels.flatten())
        idx = int(np.argmax(counts))
        dom_bgr = centers[idx].astype(np.uint8).tolist()
        # Convertir a RGB
        dom_rgb = [int(dom_bgr[2]), int(dom_bgr[1]), int(dom_bgr[0])]
        dom_hex = '#%02x%02x%02x' % tuple(dom_rgb)

        result = {
            "dominant_color_rgb": f"{dom_rgb[0]},{dom_rgb[1]},{dom_rgb[2]}",
            "dominant_color_hex": dom_hex,
            "relative_size": relative_size,
            "bbox": None if bbox is None else f"{bbox[0]},{bbox[1]},{bbox[2]},{bbox[3]}",
        }
        return result

    @staticmethod
    def describe_visual_features(features: dict) -> str:
        parts = []
        if not features:
            return ""
        if features.get("dominant_color_hex"):
            parts.append(f"Color dominante: {features['dominant_color_hex']} ({features.get('dominant_color_rgb','')})")
        if features.get("relative_size") is not None:
            parts.append(f"TamaÃ±o relativo: {features['relative_size']:.1%}")
        if features.get("bbox"):
            parts.append(f"BBox: {features['bbox']}")
        return " | ".join(parts)

def test_image_processing():
    """FunciÃ³n de prueba para procesamiento de imÃ¡genes"""
    print("ðŸ§ª Probando procesamiento de imÃ¡genes...")
    
    processor = ImageProcessor()
    
    # Crear imagen de prueba
    test_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
    
    # Probar preprocesamiento
    processed = processor.preprocess_for_classification(test_image)
    print(f"âœ… Imagen preprocesada: {processed.shape}")
    
    # Probar mejora de imagen
    enhanced = processor.enhance_image(test_image)
    print(f"âœ… Imagen mejorada: {enhanced.shape}")
    
    # Probar detecciÃ³n de objetos
    bboxes = processor.detect_objects(test_image)
    print(f"âœ… Objetos detectados: {len(bboxes)}")

if __name__ == "__main__":
    test_image_processing()
